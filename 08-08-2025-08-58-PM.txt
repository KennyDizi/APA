# Enhanced Prompt

Build a Python console loading indicator that shows a block of white squares fading to the left. The block moves from position 1 to position 10 in exactly 2.0 seconds, then reverses and moves back to position 1 in exactly 2.0 seconds, repeating while active. Show this indicator only when the LLM starts thinking (i.e., after a request is sent and before or during generation), and hide it as soon as the model finishes or as soon as the first token arrives (make this configurable).

Functional requirements:
- Visual style
  - Single-line indicator composed of 10 discrete positions (cells).
  - The visible block is a contiguous set of cells with a head cell and a left-fading tail (head is brightest white; cells to its left fade with decreasing intensity).
  - When moving right, head sits at the right edge of the block; tail fades to the left.
  - When moving left, retain the same left-fade orientation relative to the head (do not flip the gradient).
  - Default tail length: 5 cells including the head, with intensity weights [1.0, 0.7, 0.45, 0.25, 0.12].
- Motion
  - Track length: 10 cells.
  - Movement speed: exactly 2.0 seconds from cell 1 to cell 10, and 2.0 seconds back (triangular wave over a 4.0-second cycle).
  - Update only when the head changes cell index to minimize CPU use (no need for sub-cell interpolation).
- Timing
  - Use a monotonic clock and compute head index based on elapsed time and a triangular-position function. Avoid drift.
- Rendering
  - Prefer truecolor or 256-color ANSI using background color blocks so each cell looks like a white square.
  - Use U+2588 FULL BLOCK as the cell glyph by default; fall back to background-colored spaces or ASCII alternatives like "##" or "[]" if the terminal lacks Unicode or color support.
  - Provide robust fallbacks for non-TTY or limited terminals (auto-disable or degrade gracefully).
- Behavior and lifecycle
  - The indicator must run non-blocking in the background and stop immediately on completion.
  - Hide the cursor while animating and restore it on exit.
  - The indicator must not interfere with other console output and must leave the console clean (clear the indicator line on stop).
- Integration
  - Show the indicator only when the LLM starts thinking:
    - Provide simple hooks for OpenAI (Python SDK), LangChain, and LlamaIndex to start on llm_start and stop on first token or llm_end (make this behavior configurable).
    - Provide a small context manager or decorator for general-purpose async/sync calls.
  - Add a configurable debounce delay (e.g., 120 ms) before showing the indicator to avoid flicker on very fast responses.
- Configuration
  - Expose: track length (default 10), tail length and weights, cycle durations (forward/back), debounce delay, palette mode (truecolor, 256, ascii), glyph choice, show-until-first-token vs show-until-finish, and enable/disable auto-tty detection.
- Quality
  - Clean shutdown on exceptions (restore cursor and terminal state).
  - CPU usage should stay minimal (target less than 1 percent on typical hardware).
  - Include unit tests for timing, lifecycle, fallback, and rendering logic (non-visual assertions).
  - Provide type annotations and docstrings.

Non-functional:
- Python 3.10+.
- You may install third-party libraries (prefer "rich" for rendering).
- Provide clear integration instructions and examples for OpenAI Python SDK, LangChain, and LlamaIndex.


Assumptions and questions
1) Should the indicator disappear at the first streamed token or persist until the entire generation completes? Default proposal: stop on first token; add a setting to run until complete.
2) May we add "rich" as a dependency? If not, we will implement ANSI manually with a minimal fallback.
3) Which LLM stack do you use (OpenAI SDK, LangChain, LlamaIndex, others)? We will include tailored hook instructions.
4) Any constraints on terminal colors or Unicode support (CI, Windows legacy console)? We will auto-detect and provide fallbacks.
5) Do you want a label like "Thinking..." next to the indicator, or strictly the squares only?
6) Is the exact gradient mandatory, or can we fine-tune weights for best appearance per terminal?


Plan (pseudocode)
- Constants and config
  - TRACK_LEN := 10
  - FORWARD_DUR := 2.0  // seconds to go from cell 1 to 10
  - BACKWARD_DUR := 2.0 // seconds to go from 10 back to 1
  - CYCLE_DUR := FORWARD_DUR + BACKWARD_DUR  // 4.0
  - TAIL_WEIGHTS := [1.0, 0.7, 0.45, 0.25, 0.12]  // index 0 is head
  - TAIL_LEN := len(TAIL_WEIGHTS)
  - PALETTE_MODE := "auto" | "truecolor" | "256" | "ascii"
  - CELL_GLYPH := "FULL_BLOCK" (U+2588) with fallback to " " + background or "##"
  - SHOW_UNTIL := "first_token" | "finish"
  - DEBOUNCE_START_SEC := 0.12
  - MAX_FPS := 30  // safety cap; actual updates occur on index changes

- Utility: supports_tty()
  - Return sys.stdout.isatty()

- Utility: pick_palette(PALETTE_MODE)
  - If truecolor supported: build a mapping from weight to RGB whites (e.g., 255,255,255 down to gray).
  - Else if 256-color: map weights to grayscale background indices 232..255.
  - Else: ascii fallback palette using visible characters and no color.

- Function: head_index_at_time(t_elapsed)
  - t_mod := t_elapsed mod CYCLE_DUR
  - if t_mod < FORWARD_DUR:
      frac := t_mod / FORWARD_DUR  // in [0,1)
      pos := frac * (TRACK_LEN - 1)  // 0..9 linear
    else:
      frac := (t_mod - FORWARD_DUR) / BACKWARD_DUR
      pos := (1.0 - frac) * (TRACK_LEN - 1)  // 9..0 linear
  - head := round(pos)  // integer cell index
  - return clamp(head, 0, TRACK_LEN-1)

- Function: build_frame(head, palette, glyph, track_len, tail_weights)
  - For i in 0..track_len-1:
      d := head - i  // distance to the left of head
      if 0 <= d < tail_len:
        w := tail_weights[d]
        cell := colorize(glyph, weight w, palette, orientation "white fade left")
      else:
        cell := background blank or space
  - Join all cells into a single line string.
  - Return that line.

- Class: BounceFadeIndicator
  - fields:
      thread, stop_event, running_flag
      palette, glyph, track_len, tail_weights, settings (debounce, show_until)
  - method start():
      if not TTY or disabled: return no-op
      spawn thread:
        sleep DEBOUNCE_START_SEC; if stop_event set: exit
        hide cursor; with live render region:
          last_head := None
          start_time := monotonic()
          while not stop_event.is_set():
             t := monotonic() - start_time
             head := head_index_at_time(t)
             if head != last_head:
               frame := build_frame(head, palette, glyph, track_len, tail_weights)
               render frame on one line without scrolling
               last_head := head
             sleep small interval (e.g., 1/MAX_FPS) to cap CPU
        on finally: clear line, show cursor
  - method stop():
      signal stop_event; join thread with timeout

- Integration: LLMThinkingContext
  - __enter__/__exit__ or async equivalents
  - on enter: indicator.start()
  - on exit: indicator.stop()

- Integration: OpenAI SDK
  - wrap call:
    - indicator.start() when request is sent
    - if streaming:
        - stop on first token if SHOW_UNTIL == "first_token"
        - always stop at stream end
      else:
        - stop when full response arrives or on error
  - ensure try/finally for stop()

- Integration: LangChain and LlamaIndex
  - implement callback handler: on_llm_start -> start(); on_llm_new_token -> conditional stop; on_llm_end/on_llm_error -> stop()

- Error handling
  - Always restore cursor on exceptions and process exit.
  - No residual escape codes or extra lines left behind.

- Tests
  - head_index_at_time correctness at boundaries: t=0, t=2.0, t=4.0-epsilon
  - frame generation: head at 0, mid, last; verify weights applied to expected cells
  - debounce behavior: indicator does not appear for fast (< debounce) calls
  - TTY off: no output occurs
  - Start/stop idempotence; thread cleanup


Implementation guidance (no code)
- Dependencies
  - Prefer rich>=13 for rendering and cross-platform ANSI handling.
  - Use typing for strong type hints.
  - Optional: colorama on Windows if you implement raw ANSI without rich.

- Rendering details
  - Truecolor: map weight w to rgb value v = round(255 * w) and use white v,v,v as background. Keep glyph as full block or background-colored space. Ensure contrast against terminal background; if background is light, allow config to invert to black fade.
  - 256-color: convert w to grayscale index g = round(232 + w * (255 - 232)), then "on color(g)" as background. Cache pre-styled cells for each weight to avoid recomputing styles every frame.
  - ASCII fallback: use "##" for active cells with differing counts by weight (e.g., render head as "##", next as "# ", then "  "), or fixed "[]" with intensity represented by alternating patterns. Keep it readable.

- Performance
  - Update only on head index change to bound refreshes to 9 transitions per 2 seconds, i.e., 4.5 updates per second each direction. With bounce, average is roughly 4.5 updates per second. This is extremely light on CPU.
  - Precompute styled cells for each possible weight to reduce allocations and style parsing in the update loop.
  - Use monotonic clock to compute position rather than sleep-stepping to eliminate drift.

- Lifecycle and cleanup
  - When starting: optionally delay by DEBOUNCE_START_SEC to avoid quick flash on fast operations.
  - Use a daemon thread for the animator but still join on stop() to flush the final cleanup.
  - On stop: clear the indicator line (carriage return + erase to end of line) and restore cursor visibility.

- Integration notes
  - OpenAI SDK (Python):
    - Non-streaming: start before the call, stop in finally after response.
    - Streaming: start before iteration, stop either on first chunk (if configured) or at end of stream.
  - LangChain:
    - Custom callback handler: implement on_llm_start, on_llm_new_token, on_llm_end, on_llm_error. Trigger start/stop accordingly.
  - LlamaIndex:
    - Similar callback handler for llm start/end and token events.

- Configurability
  - Expose a simple factory function to build the indicator with parameters: track_len, tail_weights, speed, palette mode, glyph, debounce, show_until behavior.
  - Consider an environment variable override to disable the indicator in CI environments.

- Edge cases
  - If TRACK_LEN < TAIL_LEN, clamp the tail to track size.
  - If FORWARD_DUR or BACKWARD_DUR change, recompute CYCLE_DUR accordingly.
  - If terminal cannot do cursor hide/show, do not fail; fall back silently.

- Documentation
  - Provide docstrings for public APIs: indicator class, context manager, LLM callback adapters.
  - Document how to enable the indicator and how to disable or adjust it at runtime.


Optimization and complexity
- Original concept (naive): update at a fixed high FPS (e.g., 60), rebuilding full frames even when head position has not changed. Time per second approx O(FPS * TRACK_LEN).
- Optimized approach:
  - Update only when the head index changes: O(steps_per_second * TRACK_LEN), where steps_per_second = (TRACK_LEN - 1) / 2 seconds per pass = 4.5 for TRACK_LEN=10 and FORWARD_DUR=2. With bounce, still about 4.5 updates per second.
  - Time per update: O(TRACK_LEN) to compose the line (constant 10).
  - Memory: O(TRACK_LEN) for the current frame string plus O(TAIL_LEN) for cached styles.
  - CPU: negligible, under 1 percent on normal terminals.

Testing checklist (no code)
- Unit tests:
  - head_index_at_time: verify for a set of timestamps mapping to expected cell indices with proper clamping at edges.
  - build_frame: assert positions and weight-to-style mapping for head and tail.
  - debounce behavior: confirm no render if stop occurs before debounce.
  - start/stop reentrancy and thread termination.
  - TTY detection: no output when stdout is not a TTY.
- Manual tests:
  - Run in terminals with and without truecolor and on Windows/macOS/Linux.
  - Streamed vs non-streamed LLM calls.
  - Interleaving normal prints with the indicator to ensure no corruption.


Next steps for you
- Confirm answers to the questions above (stop on first token vs finish, dependency on rich, your LLM stack, terminal constraints).
- I will then finalize the exact parameter defaults and provide precise step-by-step implementation instructions tailored to your environment.